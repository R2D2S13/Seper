Review_Prompt='''
You are a reviewer, your task is to work hand in hand with another AI to solve a question about a certain picture,
he is responsible for breaking down the question into multiple steps,
calling different tools at each step to give answers that may appear to violate common sense due to errors in the executing tools,
and your task is to check the results of each sub question and then choose one of three actions to execute, which are Keep, Reason, Modify,
1.Keep: The answer is reasonable enough not to change.
2.Reason: The answer is correct, but further reasoning can be made to get a result closer to the original question.Then give your answr after reasoning.
3.Modify: The answer seriously violates common sense or conflicts with known facts

The information you know is as follows
Original question: The final question about the picture
Sub question: This question is designed to solve the sub-questions that arise during the course of the final question
Sub answer: The answer of the sub question generated by  another AI.
Known information: Highly credible information obtained in the reasoning process of another AI.

Remeber:
1.Image information is information with a high degree of confidence that the model gradually obtains during the inference process, which is not 100% correct,
sometimes it may be missing or contrary to new results.
2.Start by extrapolating from the original question to get information.
3.The Sub answer only needs to be a reasonable enough answer to the Sub question.

Exampls as follows:

Original question: How many muffins can each kid have for it to be fair?
Step question: find boys patch
Sub answer: You find 2 boys
Known information:
1.two boys eating muffins at a table.
2.There are 8 muffin in the image. 
Execution: Reason.The Sub answer means that there are 2 boys in the image,which matches the conditions "two boys eating muffins at a table" in Image Information.
With the number of boys and muffins already in place.The answrr to the original question is 8/2=4.

Original question: Which color is the helmet, silver or red?
Step question: What is the color of the helmet?
Sub answer: silver
Known information:
1.a man on a skateboard is crossing a street.
2.There are 1 helmet in the image.
Execution: Keep.Although the image information does not mention the color of the helmet, 
the silver in the Sub answer has a high degree of credibility in the options of the original question

Original question: Tell me about the competition between the two skyscrapers in the image
Step question:find empire state building
Sub answer:There are 2 empire state building in the image.
Known information:
The image information as follows:
1.the empire state building and the chrysler building.
Execution: Modify.The Original question refers to two skyscrapers, which are known during the model's previous reasoning are The empire state building and The chrysler building.
So there could not be 2 empire state building,one of them is the chrysler building.

Original question:{ORI}
Step question:{SQ}
Sub answer:{SA}
Known information:
{IMG} 
Execution:
'''

Review_Prompt_V2='''
You are a reviewer, your task is to work hand in hand with another AI to solve a question about a certain picture,
he is responsible for breaking down the question into multiple steps,
calling different tools at each step to give answers that may appear to violate common sense due to errors in the executing tools,
and your task is to check the results of each sub question and select an assessment level from three levels,they are sure,possible,impossible

Sure: The sub-answer matches the existing condition or question.
Possible: Although the sub-answer is not mentioned in the existing conditions, the sub-answer is reasonable as an answer to the sub-question.
Impossible: Sub answer conflicts with obvious conditions or common sense.

The information you know is as follows
Original question: The final question about the picture
Sub question: This question is designed to solve the sub-questions that arise during the course of the final question
Sub answer: The answer of the sub question generated by another AI.
Known information: Highly credible information obtained in the reasoning process of another AI.
Your answr should give both thought and review result.

Remeber:
1.Image information is information with a high degree of confidence that the model gradually obtains during the inference process, which is not 100% correct,
sometimes it may be missing or contrary to new results.
2.Start by extrapolating from the original question to get information.
3.The Sub answer only needs to be a reasonable enough answer to the Sub question.

Exampls as follows:

Original question: How many muffins can each kid have for it to be fair?
Step question: find boys patch
Sub answer: find_objects tools find 2 boys in the image
Known information:
1.two boys eating muffins at a table.
2.There are 8 muffin in the image. 
Thought: It is Sure.The Sub answer means that there are 2 boys in the image,which matches the conditions "two boys eating muffins at a table" in Image Information.
With the number of boys and muffins already in place.The answrr to the original question is 8/2=4.
ReviewResult: The answrr to the original question is 8/2=4.

Original question: Which color is the helmet, silver or red?
Step question: What is the color of the helmet?
Sub answer: The answer generated by the simple_query tool is silver
Known information:
1.a man on a skateboard is crossing a street.
2.There are 1 helmet in the image.
Thought: It is Possible.Although the image information does not mention the color of the helmet, 
the silver in the Sub answer has a high degree of credibility in the options of the original question
ReviewResult: The color of the helmet is silver

Original question: Tell me about the competition between the two skyscrapers in the image
Step question:find empire state building
Sub answer:find_objects tools find 2 empire state building in the image.
Known information:
The image information as follows:
1.the empire state building and the chrysler building.
Thought: It is Impossible.The Original question refers to two skyscrapers, 
which are known during the model's previous reasoning are The empire state building and The chrysler building.
So there could not be 2 empire state building,one of them is the chrysler building.
ReviewResult: One of the empire state building found in the image is actually chrysler building.

Original question:{ORI}
Step question:{SQ}
Sub answer:{SA}
Known information:
{IMG} 
Thought:
'''

Review_Prompt_V3 = '''
You are a reviewer, your task is to work hand in hand with another AI to solve a question about a certain picture,
he is responsible for breaking down the question into multiple steps,
calling different tools at each step to give answers that may appear to violate common sense due to errors in the executing tools,
and your task is to rethink the results of each sub question and continue reasoning based on existing results.
If the existing results are not match with the question, output impossible

The information you know is as follows
Original question: The final question about the picture
Sub question: This question is designed to solve the sub-questions that arise during the course of the final question
Sub answer: The answer of the sub question generated by another AI.
Known information: Highly credible information obtained in the reasoning process of another AI.

Exampls as follows:
Original question: Tell me about the competition between the two skyscrapers in the image
Step question:find empire state building
Sub answer:There are 2 empire state building in the image.
Known information:
The image information as follows:
1.the empire state building and the chrysler building.
Review: It is Impossible.The Original question refers to two skyscrapers, which are known during the model's previous reasoning are The empire state building and The chrysler building.
So there could not be 2 empire state building,one of them is the chrysler building.

Original question: How many muffins can each kid have for it to be fair?
Step question: find boys patch
Sub answer: You find 2 boys
Known information:
1.two boys eating muffins at a table.
2.There are 8 muffin in the image. 
Review: With the number of boys and muffins already in place.The answrr to the original question is 8/2=4.

Original question:{ORI}
Step question:{SQ}
Sub answer:{SA}
Known information:
{IMG} 
Review:

'''

Review_Prompt_V4='''
You are a reviewer,Your task is to determine whether someone's answer conflicts with common sense, 
or conflicts with existing conditions, and if the above occurs, tell the reason and answer 'yes'

examples
question: What is the color of the helmet?
answer: silver
Known information:
1.a man on a skateboard is crossing a street.
2.There are 1 helmet in the image.
ReviewResult:no,the answer is not conflict with the common sense or existing conditions.
'''

Review_Prompt_V5='''
You are a reviewer, your task is to work hand in hand with another AI to solve a question about a certain picture,
he will breaking down the question into multiple sub-questions and give his answers,while each sub-question is realated to an object in the image.
Your task is to check whether the answer meets the following two criteria and give a score with reasoning process:
1.Whether it conforms to common sense,full score of 2.5 points
2.As an answer, is it too vague?full score of 2.5 points.
Remeber:When scoring the final score, use the statement 'Final score is'

Examples as follows:
object:soap_dispenser
question:What is the material?
answer:stainless steel
score:
    - common sense:stainless steel is a common material used for soap dispensers.The score is 2.5.
    - clear:The answer is clear enough.The score is 2.5.
    - Final score is 5.

object:object
question:Who is wearing t-shirt?
answer:person
score:
    - common sense:It is common for person wearing t-shirt.The score is 2.5.
    - clear:The answer is vague.The score is 0.
    - Final score is 2.5.    

object:furniture
question:What is this furniture?
answer:a kitchen
score:
    - common sense:A kitchen is not a furniture..The score is 0.
    - clear:The answer is vague.The score is 0.
    - Final score is 0.

object:remote
question:What is the material?
answer:paper
score:
    - common sense:It is uncommon to see a paper remote.The score is 0.5.
    - clear:The answer is clear.The score is 2.5.
    - Final score is 3.

object:animal
question:What kind of animal is this?
answer:horse
score:
    - common sense:Horse is an animal.The score is 2.5.
    - clear:The answer is clear.The score is 2.5.
    - Final score is 5.

object:airplane
question:What is the material?
answer:plastic
score:
    - common sense:Plastic is not a common material for airplanes,unless it is a toy airplane.The score is 0.5
    - clear:The answer is clear.The score is 2.5.
    - Final score is 3.

object:ball
qustion:How big is the ball?
answer:big
score:
    - common sense:The score is 2.
    - clear:The answer "big" does not provide enough information to assess the cleanliness of the wood door.More specific descriptions,Such as "huge" or "small",would have been more appropriate.The score is 0.
    - Final score is 2.
(example end)

object:{object}
question:{query}
answer:{model_output}
score:
'''
Review_Prompt_with_level = '''
You are a reviewer, your task is to work hand in hand with another AI to solve a question about a certain picture,
Your task is to check whether the answer meets the following two criteria and give a judge result with reasoning process:
1.Is it possible that this answer is the correct answer??
2.Is it this answer clear enough?
Remeber:For the judgment result of each question, output Sure, possible, or impossible.

Examples as follows:
object:airplane
question:What is the material?
answer:plastic
judge:
- Is it possible that this answer is the correct answer??:Plastic is not a common material for airplanes,unless it is a toy airplane.It is possible.
- Is it this answer clear enough?:Sure.It is clear enough.

object:foo
question:What is the object behind the skateboard
answer:Unknown
judge:
- Is it possible that this answer is the correct answer??:'Unkown' should be the answer of question.Because the purpose of another AI is to output an answer, not to tell the user that he doesn't know anything.It is impossible.
- Is it this answer clear enough?:Impossible.It is vague.
(Examples finished)

object:{object}
question:{query}
answer:{model_output}
judge:
'''

Review_Prompt_with_level_V2 = '''
You are a reviewer, your task is to work hand in hand with another AI to solve a question about a certain picture,
Your task is to check whether the answer meets the following two criteria and give a judge result with reasoning process:
1.Is it possible that this answer is the correct answer?Output Sure, possible, or impossible.
2.Is it this answer clear enough?Output yes or no.


Examples as follows:
object:airplane
question:What is the material?
answer:plastic
judge:
- Is it possible that this answer is the correct answer?:Possible.Plastic is not a common material for airplanes,unless it is a toy airplane.
- Is it this answer clear enough?:Yes.It is clear enough.

object:foo
question:What is the object behind the skateboard
answer:Unknown
judge:
- Is it possible that this answer is the correct answer?:Impossible.'Unkown' should be the answer of question.Because the purpose of another AI is to output an answer, not to tell the user that he doesn't know anything.
- Is it this answer clear enough?:No.It is vague.

object:fruit
question:Is the fruit type apple or banana?
answer:pear
judge:
- Is it possible that this answer is the correct answer?:Impossible.Obviously this question is a two-option multiple-choice question.But bar is not even an option in the question.
- Is it this answer clear enough?:Yes,it is clear.

object:baz
question:What is the side of baz in the image?
answer:No baz found in the image
judge:
- Is it possible that this answer is the correct answer?:Impossible.Since the question asks about the location of the bag, there can be no bag in the picture.
- Is it this answer clear enough?:Yes,it is clear.


(Examples finished)

object:{(object)}
question:{(query)}
answer:{(model_output)}
judge:
'''

Review_Prompt_for_OK_VQA = '''
You are a reviewer, your task is to work hand in hand with another AI to solve a question about a certain picture,
Your task is to check whether the answer meets the following two criteria and give a judge result with thinking process:
whether this answer is the in the domain of expected result.Output Sure, possible, or impossible.

Examples as follows:

question:What is the material of the airplane?
answer:plastic
thinking:
1.What is the question expected answer?
The question expected answer should be type of material.
2.Is the answer 'plastic' is a type of material.
Yes.Of course plastic is a type of material.
judge:
Sure.Plastic is type of material.


question:What is the object behind the skateboard in the image?
answer:Unknown
thinking:
1.What is the question expected answer?
The question expected answer should be an object.
2.Is 'unknown' a type of object?
No.'unknown' is not any object.
judge:
Impossible.'Unkown' is not object.


question:What are the logo on the vehicles?
answer:Number 6.
thinking:
1.What is the question expected answer?
The question expected answer is a type of logo of something painting in the vehicles.
2.Is 'number' six type of logo?
Yes.The number may be the number of the vehicle.And number could be the content of logo.
judge:
Possible.The number may be the logo of the vehicle.

question:What appliance is that money inside?
answer:Refrigerator.
thinking:
1.What is the question expected answer?
The question expected answer is a type of appliance,and it should be type of container.
2.Is 'Refrigerator' both an appliance and container?
Yes.Althought it is not common.But 'Refrigerator' is in the domain of expected answer.
judge:
Possible.Althoug it is not common,but refrigerator is both appliance and container.

question:Who will love this suit?
answer:No one.
thinking:
1.What is the question expected answer?
The question expected answer is 'who'.It can be occupation, gender, and everything else that is used to describe people
2.Is 'No one' can be used to describe people?
No.'No one' means nobody,which is not a expected result.
judge:
Impossible.The answer did not give any word about 'who''s feature.

question:What kind of horse is it?
answer:horse.
thinking:
1.What is the question expected answer?
The question expected answer should type of horse.
2.Is 'horse' type of horse?
No.'Horse' is not a specific type.The answer should be more clear of what horse it is/
judge:
Impossible.The answer should be the breed of the horse, not a simple repetition of the word 'horse'

(Examples finished)


# Remeber:It is necessary to reason from the problem through plausibility and external knowledge
question:{(query)}
answer:{(model_output)}
thinking:
1.What is the question expected answer?
'''

Review_Prompt_for_OK_VQA = '''
You are a reviewer, your task is to work hand in hand with another AI to solve a question about a certain picture,
Your task is to check whether the answer meets the following two criteria and give a judge result with thinking process:
whether this answer is the in the domain of expected result.Output Sure, possible, or impossible.

Examples as follows:

question:What is the material of the airplane?
answer:plastic
thinking:
1.What is the question expected answer?
The question expected answer should be type of material.
2.Is the answer 'plastic' is a type of material.
Yes.Of course plastic is a type of material.
judge:
Sure.Plastic is type of material.


question:What is the object behind the skateboard in the image?
answer:Unknown
thinking:
1.What is the question expected answer?
The question expected answer should be an object.
2.Is 'unknown' a type of object?
No.'unknown' is not any object.
judge:
Impossible.'Unkown' is not object.


question:What are the logo on the vehicles?
answer:Number 6.
thinking:
1.What is the question expected answer?
The question expected answer is a type of logo of something painting in the vehicles.
2.Is 'number' six type of logo?
Yes.The number may be the number of the vehicle.And number could be the content of logo.
judge:
Possible.The number may be the logo of the vehicle.

question:What appliance is that money inside?
answer:Refrigerator.
thinking:
1.What is the question expected answer?
The question expected answer is a type of appliance,and it should be type of container.
2.Is 'Refrigerator' both an appliance and container?
Yes.Althought it is not common.But 'Refrigerator' is in the domain of expected answer.
judge:
Possible.Althoug it is not common,but refrigerator is both appliance and container.

question:Who will love this suit?
answer:No one.
thinking:
1.What is the question expected answer?
The question expected answer is 'who'.It can be occupation, gender, and everything else that is used to describe people
2.Is 'No one' can be used to describe people?
No.'No one' means nobody,which is not a expected result.
judge:
Impossible.The answer did not give any word about 'who''s feature.

question:What kind of horse is it?
answer:horse.
thinking:
1.What is the question expected answer?
The question expected answer should type of horse.
2.Is 'horse' type of horse?
No.'Horse' is not a specific type.The answer should be more clear of what horse it is/
judge:
Impossible.The answer should be the breed of the horse, not a simple repetition of the word 'horse'

(Examples finished)


# Remeber:It is necessary to reason from the problem through plausibility and external knowledge
question:{(query)}
answer:{(model_output)}
thinking:
1.What is the question expected answer?
'''

Review_Prompt_for_find = '''The codeline "CODELINE" fail and return empty list, the reason may be that there is no such object in the image, 
or the object detection model the find method relies on is not powerful enough to detect the object.

The object required to be find:OBJECT.
The possible location of OBJECT:
LOCATION

Can you based on the previous information and write new code to find the object?
- If you can
    Write a new code based on previous information.Here are some ways you can try to improve the original code:
    - If you do not know the location,try changing the alternative name of the object need to be find.
    - If you do know the location,improve the logic of the original code based on the information.
- If you can't
    Do not write code!Explain to the me why you can not find the object.If there are no object in the image,tell me.

Remeber:You don't need to look for any other objects other than the ones that are required.'''


Review_Prompt_for_find_V2= '''The codeline "CODELINE" fail and return empty list, the reason may be that 
object detection model the find method relies on is not powerful enough to detect the object.But OBJECT is very
possible in the image.Try to find the object.

The object required to be find:OBJECT.
The possible location of OBJECT:
LOCATION

Write a new code based on previous information.Here are some ways you can try to improve the original code:
- Try changing the alternative name of the object need to be find(Use up to 5 alternate names).
- Improve the logic of the original code based on the information.
'''

Review_Prompt_for_find_V3= '''The codeline "CODELINE" fail and return empty list, the reason may be that 
object detection model the find method relies on is not powerful enough to detect the object.But OBJECT is very
possible in the image.Try to find the object.

The object required to be find:OBJECT.
The possible location of OBJECT:
LOCATION

Write a new code based on previous information.Here are some ways you can try to improve the original code:
- Try changing the alternative name of the object need to be find(Use up to 5 alternate names).
- Improve the logic of the original code based on the information.
- Do no use "CODELINE" statement again.
'''

Get_Location_prompt = '''

You are an expert in textual reasoning, and you are good at reasoning from textual information to get answers to questions.
I'm going to give you a description of an image and a question that you need to deduce from it.

ImageCaption:{(caption)}
Question:Where is the {(object)}
'''

Get_Location_prompt_v2= '''
You are an expert in textual reasoning, and you are good at reasoning from textual information to get answers to questions.
Now here's a image with an AI-generated description of that image(not 100% correct), and the query designed for that image.
You need to speculate on the answer to another question based on the original query and the description.


Here are some examples:
(Example1)
ImageCaption:The image depict an aux and bar.
OriginalQuery:The color of the top of the aux is green or blue?
Question1: Does foo exists in the image?
Answer1: Although the existence of foo is not mentioned in the caption, his presence is implied in the query, because if foo does not exist, the question becomes unanswerable.Yes,it exists.
Question2: If foo exist,what is it possible location?
Answer2: I know its existence,but i can not deduce foo's location from the previous information 

(Example2)
ImageCaption:There is an bar in the left of the foo.
OriginalQuery:The color of the aux of foo is green or blue?
Question1: Does aux exists in the image?
Answer1: If aux does not exist, there will be no answers to the query.Althought it does not mention in the caption,the aux exists.
Question2: If aux exist,what is it possible location?
Answer2: Aux exist in the image,but the information of caption is not enough for deducing.

(Example3)
ImageCaption:There are an foo and an aux in the image.
OriginalQuery:Can you see bar or aux in the image?
Question1: Does bar exists in the image?
Answer1: No,it does not exist.Based on the image caption and there is no affirmation of its existence in the query.So bar does not exist in the image.
Question2: If bar exist,what is it possible location?
Answer2: Bar does not exist in the image.
(Example finished)

ImageCaption:{(caption)}
OriginalQuery:{(query)}
Question1:Based on the the query "{(query)}" and image caption,Does "{(object)}" exists in the image?
Question2:If "{(object)}" exist,what is it possible location?
Remeber:
- Learn from previous examples.
- The information in the query more important than the information in the caption,because caption is generated by ai that not 100 percent correct.
- The "{(object)}" may just be a synonym for an object in the image.Use this feature.
'''


Get_Location_prompt_v3= '''
You are an expert in textual reasoning, and you are good at reasoning from textual information to get answers to questions.
Now here's a image with an AI-generated description of that image(not 100% correct), and the query designed for that image.
You need to speculate on the answer to another question based on the original query and the description.


Here are some examples:
(Example1)
ImageCaption:The image depict an aux and bar.
OriginalQuery:The color of the top of the aux is green or blue?
Question1: Does foo exists in the image?
Answer1: Although the existence of foo is not mentioned in the caption, its presence is implied in the query, because if foo does not exist, the question becomes unanswerable.Yes,it exists.
Question2: If foo exist,what is it possible location?
Answer2: I know its existence,but i can not deduce foo's location from the previous information 
Output:
{
    'existence':'Sure',
    'possible_location':'Unknown'
}

(Example2)
ImageCaption:There is an bar in the left of the foo.
OriginalQuery:The color of the aux of foo is green or blue?
Question1: Does aux exists in the image?
Answer1: If aux does not exist, there will be no answers to the query.Althought it does not mention in the caption,the aux exists.
Question2: If aux exist,what is it possible location?
Answer2: Aux exist in the image,but the information of caption is not enough for deducing.
Output:
{
    'existence':'Sure',
    'possible_location':'Unknown'
}

(Example3)
ImageCaption:There are an foo and an aux in the image.
OriginalQuery:Can you see bar or aux in the image?
Question1: Does bar exists in the image?
Answer1: No,it does not exist.Based on the image caption and there is no affirmation of its existence in the query.So bar does not exist in the image.
Question2: If bar exist,what is it possible location?
Answer2: Bar does not exist in the image.
Output:
{
    'existence':'Impossible',
    'possible_location':'Unknown'
}
(Example finished)

ImageCaption:{(caption)}
OriginalQuery:{(query)}
Question1:Based on the the query "{(query)}" and image caption,Does "{(object)}" exists in the image?
Question2:If "{(object)}" exist,what is it possible location?

Remeber:
- Learn from previous examples.
- The information in the query more important than the information in the caption,because caption is generated by ai that not 100 percent correct.
- The "{(object)}" may just be a synonym for an object in the image.Use this feature.
- Your final output should be same with the output format as follows:
Output format:
Answer1:...
Answer2:...
{
    'existence':'Sure' or 'Impossible',
    'possible_location':'The possible location of {(object)}'
}
'''

simple_query_gqa_fix_prompt =f'''Here are some suggestion for you to improve the code:
1.Replace the question parameter of 'simple_query' function.
2.Use other function to seek more information of the image.
For example,if there are options given or implied in the question,you can use best_text_match with giving options.'''

simple_query_ok_vqa_fix_prompt ='''It seems that the model simple_query relies on is limiting its ability to answer this question correctly.
Here is the detaild caption for image:
IMAGE_CAPTION_INSERT_HERE
1.Can you deduce from the image caption what the expected answer 'EXPECTED_RESULT_INSERT_HERE' is for the question?
- If you can,try to direct append 'EXPECTED_RESULT_INSERT_HERE' into guesses.
- If you can not,use llm_query deduce from the image_caption to replace simple_query method as follows:
```
    caption = image.caption
    caption_query = f"Base on the image caption \{caption\}.QUERY_INSERT_HERE".format(people_on_bikes)
    EXPECTED_RESULT_INSERT_HERE = llm.query(caption_query)
```
2.Rethinking the question.Can "QUERY_INSERT_HERE" be answered without image content?
- If it can.Direct use 'EXPECTED_RESULT_INSERT_HERE = llm_query('QUERY_INSERT_HERE')' replace simple_query method of this line of code.
Generate a complete function startswith 'def execute_command' based on above suggestion.'''

import sys
sys.path.append('.')
from LLM.chatgpt_function_model import LevelReviewFunction,TemplateChatGpt,FindReviewFunction,LevelReviewFunctionForOKVQA

fn2ReviewLLm = {
    'GQA':{
    'find':FindReviewFunction(prompt_template=Get_Location_prompt_v3),
    'simple_query':LevelReviewFunction(prompt_template=Review_Prompt_with_level_V2,parse_args={'n':3})
    },
    'OKVQA':{
    'simple_query':LevelReviewFunctionForOKVQA(prompt_template=Review_Prompt_for_OK_VQA,parse_args={'n':3},negative_threshold=2)
    },
    'GQA_json':{
    'find':FindReviewFunction(prompt_template=Get_Location_prompt_v3),
    'simple_query':LevelReviewFunction(prompt_template=Review_Prompt_with_level_V2,parse_args={'n':3})
    },
}
fix_prompt_dict = {
    'GQA':{
        'simple_query':simple_query_gqa_fix_prompt
    },
    'OKVQA':{
        'simple_query':simple_query_ok_vqa_fix_prompt
    }
}
