from pathlib import Path
from typing import Literal
import decord
from decord import cpu, gpu
import numpy as np
from PIL import Image
import pandas as pd
from torch.utils.data import Dataset
import os
import json


class MyDataset(Dataset):
    def __init__(self, file_name, data_path='/.do/data/meta_data', input_type='image', image_transforms=None, fps=30, max_num_frames=30,
                 max_samples=None, start_sample=0, **kwargs):
        """
        Args:
            data_path (str): Path to the data folder
            input_type (str): Type of input. One of ["image", "video"]
            image_transforms (callable, optional): Optional transform to be applied on an image. Only used if input_type
                is "image".
            fps (int): Frames per second. Only used if input_type is "video".
            max_num_frames (int): Maximum number of frames to use. Only used if input_type is "video".
            max_samples (int, optional): Maximum number of samples to load. If None, load all samples.
            start_sample (int, optional): Index of the first sample to load. If None, start from the beginning.
        """
        self.file_name = file_name
        self.data_path = Path(data_path)
        self.input_type = input_type
        self.image_transforms = image_transforms
        self.fps = fps
        self.max_num_frames = max_num_frames

        # Load questions, answers, and image ids
        with open(self.data_path / f'{self.file_name}.csv', 'r') as f:
            # The csv has the rows [query, answer, image_name or video_name]
            self.df = pd.read_csv(f, index_col=None, keep_default_na=False)

        if start_sample is not None:
            if max_samples is not None:
                self.df = self.df.iloc[start_sample:start_sample + max_samples]
            else:
                self.df = self.df.iloc[start_sample:]

        self.n_samples = len(self.df)

    def get_sample_path(self, index):
        sample_name = self.df.iloc[index][f"{self.input_type}_name"]
        return sample_name

    def get_image(self, image_path):
        with open(image_path, "rb") as f:
            pil_image = Image.open(f).convert("RGB")
        if self.image_transforms:
            image = self.image_transforms(pil_image)[:3]
        else:
            image = pil_image
        return image

    def get_video(self, video_path):
        # If fixed width and height are required, VideoReader takes width and height as arguments.
        video_reader = decord.VideoReader(str(video_path), num_threads=1, ctx=cpu(0))
        decord.bridge.set_bridge('torch')
        vlen = len(video_reader)
        original_fps = video_reader.get_avg_fps()
        num_frames = int(vlen * self.fps / original_fps)
        num_frames = min(self.max_num_frames, num_frames)
        frame_idxs = np.linspace(0, vlen, num_frames, endpoint=False).astype(np.int)
        video = video_reader.get_batch(frame_idxs).byte()
        video = video.permute(0, 3, 1, 2)
        return video

    def __getitem__(self, index):

        out_dict = self.df.iloc[index].to_dict()

        sample_path = self.get_sample_path(index)

        # Load and transform image
        image = self.get_image(sample_path) if self.input_type == "image" else self.get_video(sample_path)

        out_dict["image"] = image
        out_dict["index"] = index
        
        return out_dict

    def __len__(self):
        return self.n_samples
    
class JsonDataset(Dataset):
    '''Note:This dataset is used for json file generated by prog_env/plan_env'''
    def __init__(self,json_dir,
                 start_sample:int = 0,
                 select_columns:list[str] = None,
                 sample_list:object=None,
                 max_samples:int = None,
                 list_selected_mode:Literal['all','first','last']='first') -> None:
        super().__init__()
        self.json_dir = json_dir
        self.all_json_files=[]
        if sample_list is not None:
            if isinstance(sample_list,str):
                with open(sample_list,'r') as f:
                    sample_list = json.load(f)
        for file in os.listdir(json_dir):
            if file.endswith('.json'):
                if sample_list is not None:
                    sample_id = file.split('.')[0].strip()
                    if sample_id in sample_list:
                        self.all_json_files.append(file)
                else:
                    self.all_json_files.append(file)
        if max_samples is not None:
            self.all_json_files = self.all_json_files[start_sample:]
        else:
            self.all_json_files = self.all_json_files[start_sample:start_sample+max_samples]
        if select_columns is None:
            select_columns = ['query','label','image_path','code']
        self.select_columns = select_columns
        self.list_selected_mode = list_selected_mode

    def __getitem__(self, index):

        fname = self.all_json_files[index]
        sample_id = fname.split('.')[0]
        fpath = os.path.join(self.json_dir,fname)
        with open(fpath,'r') as f:
            content = json.load(f)
            out_dict = {k:v for k,v in content.items() if k in self.select_columns}
            for k,v in out_dict.items():
                if isinstance(v,list):
                    if self.list_selected_mode == 'all':
                        pass
                    elif self.list_selected_mode == 'first':
                        v = v[0]
                        out_dict[k]=v
                    elif self.list_selected_mode == 'last':
                        v = v[-1]
                        out_dict[k]=v
        out_dict['sample_id'] = sample_id
        out_dict['image_name'] = out_dict['image_path']
        return out_dict

    def __len__(self):
        return len(self.all_json_files)

if __name__=='__main__':
    from torch.utils.data.dataloader import DataLoader
    batch_size = 5
    dataset = MyDataset(file_name='gqa_structual')
    dataloader = DataLoader(dataset = dataset,batch_size = batch_size)
    for batch in dataloader:
        print(batch)
        break