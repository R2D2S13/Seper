# For example:
multiprocessing: True
path_pretrained_models: '/.t/pretrained_models'
key_pooling: True
prompt_file: /.do/prompts/viper_GQA.prompt
vision_seeker_name: 'IBLIP'

prog_env:
    inject_html: False
    code_check: True
    save_var: False
    replan: True
    iterate_refine: False
    function_check_list: []


code_generation:
    model: gpt-3.5-turbo-16k-0613
    input_image_varname: image
    image_preprocess: null
    output_type: return
    result_varname_proxy: ANSWER
    function_name: 'def execute_command'
    parse_args: 
        temperature: 0                                                       
        max_tokens: 512  

code_execution:
    api_file: /.do/vision_processes/image_patch.py

load_models:                                        # Which pretrained models to load
    maskrcnn: False
    clip: False
    glip: False
    owlvit: False
    tcl: False
    gpt3_qa: True
    gpt3_general: True
    gpt3_guess: True
    depth: True
    blip: True
    saliency: False
    xvlm: True
    codex: True
    GD: True
    GDSAM: False
    IBLIP: True

detect_thresholds:                                  # Thresholds for the models that perform detection
    glip: 0.5
    maskrcnn: 0.8
    owlvit: 0.1
    GD_BOX: 0.30
    GD_TEXT: 0.30

simple_query:
    model: blip

ratio_box_area_to_image_area: 0.03                  # Any detected patch under this size will not be returned
crop_larger_margin: False                           # Increase size of crop by 10% to include more context

verify_property:                                    # Parameters for verify_property
    model: xvlm                                     # Model to use for verify_property
    thresh_clip: 0.6
    thresh_tcl: 0.25
    thresh_xvlm: 0.6

best_match_model: xvlm                              # Which model to use for best_[image, text]_match

gpt3:                                               # GPT-3 configuration
    n_votes: 1                                      # Number of tries to use for GPT-3. Use with temperature > 0
    qa_prompt: ./prompts/gpt3/gpt3_qa.txt
    guess_prompt: /.do/prompts/gpt3/gpt3_process_guess.txt
    temperature: 0.                                 # Temperature for GPT-3. Almost deterministic if 0
    model: gpt-3.5-turbo-16k-0613                   # See openai.Model.list() for available models


IBLIP:
    weight_path: /.tblip-vicuna-7b/
GD:
    config_path: /.ngdinoForViper/groundingdino/config/GroundingDINO_SwinT_OGC.py
    weight_path: /.ngdinoForViper/weights/groundingdino_swint_ogc.pth
codex:
    temperature: 0.                                 # Temperature for Codex. (Almost) deterministic if 0
    best_of: 1                                      # Number of tries to choose from. Use when temperature > 0
    max_tokens: 512                                 # Maximum number of tokens to generate for Codex
    prompt: ./prompts/chatapi.prompt                # Codex prompt file, which defines the API. (doesn't support video for now due to token limits)
    model: gpt-3.5-turbo                            # Codex model to use. [gpt-3.5-turbo, gpt-4]. See openai.Model.list() for available models
SAM:
    weight_path: 'sam/sam_vit_h_4b8939.pth'
    
# blip_v2_model_type: blip2-lora   # Change to blip2-flan-t5-xl for smaller GPUs
blip_path: '/.Tplus/vipergptplus/model/blip2-flan-t5-xxl'
blip_half_precision: True
blip_v2_model_type: 'blip2-flan-t5-xxl'